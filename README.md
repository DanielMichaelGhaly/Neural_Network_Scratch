# Neural_Network_Scratch

A Python-based educational project demonstrating how to build a neural network library from the ground up—no dependencies like TensorFlow or PyTorch. Inspired by the concepts in Neural Network from Scratch | Mathematics & Python Code.

Table of Contents:

Overview
Features
Math & Theory
Getting Started


Overview

This library serves as an educational tool, showing the underpinnings of neural networks—how to model layers, activation functions, forward propagation, and the backpropagation algorithm using pure Python. It's designed for both learning and teaching.

Features

Build neural networks with customizable layers

Implement core activation functions (sigmoid, tanh, ReLU, softmax)

Compute derivatives for backpropagation

Train models through gradient-based optimization

Visualize training progress with built-in plotting options

Math & Theory

The code closely mirrors the mathematical notation presented in the video:

Computes pre-activations: 
z=W⋅x+b

Applies activation functions: 
a=f(z)

Calculates gradients:
f′(z) for backpropagation

Getting Started
Prerequisites

Python 3.7 or newer

numpy

(Optional) matplotlib for visualizations

pip install numpy matplotlib

Installation

Clone the repo:

git clone <repository-url>
cd neural-network-from-scratch

